{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeGPT\n",
    "\n",
    "> Unlock the power of accurate predictions and confidently navigate uncertainty. Reduce uncertainty and resource limitations. With TimeGPT, you can effortlessly access state-of-the-art models to make data-driven decisions. Whether you're a bank forecasting market trends or a startup predicting product demand, TimeGPT democratizes access to cutting-edge predictive insights, eliminating the need for a dedicated team of machine learning engineers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Nixtla's TimeGPT is a generative pre-trained model trained to forecast time series data. The inputs to TimeGPT are time series data, and the model generates forecast outputs based on these. The input involves providing the historical data and potentially defining parameters such as the forecast horizon. TimeGPT can be used across a plethora of tasks including demand forecasting, anomaly detection, financial forecasting, and more. \n",
    "\n",
    "The TimeGPT model \"reads\" time series data much like the way humans read a sentence â€“ from left to right. It looks at a chunk of past data, which we can think of as \"tokens\", and predicts what comes next. This prediction is based on patterns the model identifies in past data, much like how a human would predict the end of a sentence based on the beginning.\n",
    "\n",
    "The TimeGPT API provides an interface to this powerful model, allowing users to leverage its forecasting capabilities to predict future events based on past data. With this API, users can not only forecast future events but also delve into various time series-related tasks, such as what-if scenarios, anomaly detection, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![figure](./img/timegpt-arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp timegpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from fastcore.test import test_eq, test_fail\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "logging.getLogger('statsforecast').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class TimeGPT:\n",
    "    \"\"\"\n",
    "    A class used to interact with the TimeGPT API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, token: str):\n",
    "        \"\"\"\n",
    "        Constructs all the necessary attributes for the TimeGPT object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        token : str\n",
    "            The authorization token to interact with the TimeGPT API.\n",
    "        \"\"\"\n",
    "        self.token = token\n",
    "        self.api_url = 'https://dashboard.nixtla.io/api'\n",
    "        self.weights_x: pd.DataFrame = None\n",
    "\n",
    "    @property\n",
    "    def request_headers(self):\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"authorization\": f\"Bearer {self.token}\"\n",
    "        }\n",
    "        return headers\n",
    "        \n",
    "    def _parse_response(self, response) -> Dict:\n",
    "        \"\"\"Parses responde.\"\"\"\n",
    "        response.raise_for_status()\n",
    "        try:\n",
    "            resp = response.json()\n",
    "        except Exception as e:\n",
    "            raise Exception(response)\n",
    "        return resp\n",
    "\n",
    "    def _input_size(self, freq: str):\n",
    "        response_input_size = requests.post(\n",
    "            f'{self.api_url}/timegpt_input_size',\n",
    "            json={'freq': freq}, \n",
    "            headers=self.request_headers,\n",
    "        )\n",
    "        response_input_size = self._parse_response(response_input_size)\n",
    "        return response_input_size['data']\n",
    "\n",
    "    def _validate_inputs(\n",
    "            self,\n",
    "            df: pd.DataFrame,\n",
    "            X_df: pd.DataFrame,\n",
    "            id_col: str,\n",
    "            time_col: str,\n",
    "            target_col: str,\n",
    "        ):\n",
    "        renamer = {\n",
    "            id_col: 'unique_id',\n",
    "            time_col: 'ds',\n",
    "            target_col: 'y'\n",
    "        }\n",
    "        df = df.rename(columns=renamer)\n",
    "        drop_uid = False\n",
    "        if 'unique_id' not in df.columns:\n",
    "            # Insert unique_id column\n",
    "            df = df.assign(unique_id='ts_0')\n",
    "            drop_uid = True\n",
    "        if X_df is not None:\n",
    "            X_df = X_df.rename(columns=renamer)\n",
    "            if 'unique_id' not in df.columns:\n",
    "                X_df = X_df.assign(unique_id='ts_0')\n",
    "        return df, X_df, drop_uid\n",
    "\n",
    "    def _validate_outputs(\n",
    "            self,\n",
    "            fcst_df: pd.DataFrame,\n",
    "            id_col: str,\n",
    "            time_col: str,\n",
    "            target_col: str,\n",
    "            drop_uid: bool,\n",
    "        ):\n",
    "        renamer = {\n",
    "            'unique_id': id_col,\n",
    "            'ds': time_col,\n",
    "            'target_col': target_col,\n",
    "        }\n",
    "        if drop_uid:\n",
    "            fcst_df = fcst_df.drop(columns='unique_id')\n",
    "        fcst_df = fcst_df.rename(columns=renamer)\n",
    "        return fcst_df\n",
    "\n",
    "    def _preprocess_inputs(\n",
    "            self, \n",
    "            df: pd.DataFrame, \n",
    "            h: int,\n",
    "            freq: str,\n",
    "            X_df: Optional[pd.DataFrame] = None,\n",
    "        ):\n",
    "        input_size = self._input_size(freq)\n",
    "        y_cols = ['unique_id', 'ds', 'y']\n",
    "        y = df[y_cols].groupby('unique_id').tail(input_size + h)\n",
    "        to_dict_args = {'orient': 'split'}\n",
    "        if 'index' in inspect.signature(pd.DataFrame.to_dict).parameters:\n",
    "            to_dict_args['index'] = False\n",
    "        y = y.to_dict(**to_dict_args)\n",
    "        x_cols = df.drop(columns=y_cols).columns.to_list()\n",
    "        if len(x_cols) == 0:\n",
    "            x = None\n",
    "        else:\n",
    "            x = pd.concat([df[['unique_id', 'ds'] + x_cols].groupby('unique_id').tail(input_size + h), X_df])\n",
    "            x = x.sort_values(['unique_id', 'ds'])\n",
    "            x = x.to_dict(**to_dict_args)\n",
    "        return y, x, x_cols\n",
    "\n",
    "    def _multi_series(\n",
    "            self,\n",
    "            df: pd.DataFrame,\n",
    "            h: int,\n",
    "            freq: str,\n",
    "            X_df: Optional[pd.DataFrame] = None,\n",
    "            level: Optional[List[int]] = None,\n",
    "            finetune_steps: int = 0,\n",
    "            clean_ex_first: bool = True,\n",
    "        ):\n",
    "        y, x, x_cols = self._preprocess_inputs(df=df, h=h, freq=freq, X_df=X_df)\n",
    "        payload = dict(\n",
    "            y=y,\n",
    "            x=x,\n",
    "            fh=h,\n",
    "            freq=freq,\n",
    "            level=level,\n",
    "            finetune_steps=finetune_steps,\n",
    "            clean_ex_first=clean_ex_first,\n",
    "        )\n",
    "        response_timegpt = requests.post(\n",
    "            f'{self.api_url}/timegpt_multi_series',\n",
    "            json=payload, \n",
    "            headers=self.request_headers,\n",
    "        )\n",
    "        response_timegpt = self._parse_response(response_timegpt)\n",
    "        if 'weights_x' in response_timegpt['data']:\n",
    "            self.weights_x = pd.DataFrame({\n",
    "                'features': x_cols,\n",
    "                'weights': response_timegpt['data']['weights_x'],\n",
    "            })\n",
    "        return pd.DataFrame(**response_timegpt['data']['forecast'])\n",
    "\n",
    "    def forecast(\n",
    "            self,\n",
    "            df: pd.DataFrame,\n",
    "            h: int,\n",
    "            freq: str,    \n",
    "            id_col: str = 'unique_id',\n",
    "            time_col: str = 'ds',\n",
    "            target_col: str = 'y',\n",
    "            X_df: Optional[pd.DataFrame] = None,\n",
    "            level: Optional[List[int]] = None,\n",
    "            finetune_steps: int = 0,\n",
    "            clean_ex_first: bool = True,\n",
    "        ):\n",
    "        \"\"\"Forecast your time series using TimeGPT.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame\n",
    "            The DataFrame on which the function will operate. Expected to contain at least the following columns:\n",
    "            - time_col:\n",
    "                Column name in `df` that contains the time indices of the time series. This is typically a datetime\n",
    "                column with regular intervals, e.g., hourly, daily, monthly data points.\n",
    "            - target_col:\n",
    "                Column name in `df` that contains the target variable of the time series, i.e., the variable we \n",
    "                wish to predict or analyze.\n",
    "            Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:\n",
    "            - id_col:\n",
    "                Column name in `df` that identifies unique time series. Each unique value in this column\n",
    "                corresponds to a unique time series.\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        freq : str\n",
    "            Frequency of the data.\n",
    "            See [pandas' available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).\n",
    "        id_col : str (default='unique_id')\n",
    "            Column that identifies each serie.\n",
    "        time_col : str (default='ds')\n",
    "            Column that identifies each timestep, its values can be timestamps or integers.\n",
    "        target_col : str (default='y')\n",
    "            Column that contains the target.\n",
    "        X_df : pandas.DataFrame, optional (default=None)\n",
    "            DataFrame with [`unique_id`, `ds`] columns and `df`'s future exogenous.\n",
    "        level : List[float], optional (default=None)\n",
    "            Confidence levels between 0 and 100 for prediction intervals.\n",
    "        finetune_steps : int (default=0)\n",
    "            Number of steps used to finetune TimeGPT in the\n",
    "            new data.\n",
    "        clean_ex_first : bool (default=True)\n",
    "            Clean exogenous signal before making forecasts\n",
    "            using TimeGPT.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        fcsts_df : pandas.DataFrame\n",
    "            DataFrame with TimeGPT forecasts for point predictions and probabilistic\n",
    "            predictions (if level is not None).\n",
    "        \"\"\"\n",
    "        df, X_df, drop_uid = self._validate_inputs(\n",
    "            df=df,\n",
    "            X_df=X_df,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "        )\n",
    "        fcst_df = self._multi_series(\n",
    "            df=df, \n",
    "            h=h,\n",
    "            freq=freq,\n",
    "            X_df=X_df,\n",
    "            level=level, \n",
    "            finetune_steps=finetune_steps,\n",
    "            clean_ex_first=clean_ex_first,\n",
    "        )\n",
    "        fcst_df = self._validate_outputs(\n",
    "            fcst_df=fcst_df,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "            drop_uid=drop_uid,\n",
    "        )\n",
    "        return fcst_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TimeGPT.__init__, title_level=3, name='TimeGPT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can instantiate the `TimeGPT` class providing your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test input_size\n",
    "test_eq(\n",
    "    timegpt._input_size('D'),\n",
    "    28,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TimeGPT.forecast, title_level=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start to make forecasts! Let's import an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/air_passengers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('timestamp').plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can forecast this dataset. We observe that this dataset has monthly frequency. We have to pass the right pandas frequency to `TimeGPT` to have the right forecasts. In this case 'MS'. Let's forecast the next 12 observations. In this case we also have to define:\n",
    "\n",
    "- `time_col`: Column that identifies the datestamp column.\n",
    "- `target_col`: The variable that we want to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt_fcst_df = timegpt.forecast(df=df, h=12, freq='MS', time_col='timestamp', target_col='value')\n",
    "timegpt_fcst_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, timegpt_fcst_df]).set_index('timestamp').plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also produce a larger forecast horizon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt_fcst_df = timegpt.forecast(df=df, h=36, freq='MS', time_col='timestamp', target_col='value')\n",
    "timegpt_fcst_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, timegpt_fcst_df]).set_index('timestamp').plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction intervals provide a measure of the uncertainty in the forecasted values. In time series forecasting, a prediction interval gives an estimated range within which a future observation will fall, based on the level of confidence or uncertainty you set. This level of uncertainty is crucial for making informed decisions, risk assessments, and planning.\n",
    "\n",
    "For instance, a 95% prediction interval means that 95 out of 100 times, the actual future value will fall within the estimated range. Therefore, a wider interval indicates greater uncertainty about the forecast, while a narrower interval suggests higher confidence.\n",
    "\n",
    "When using TimeGPT for time series forecasting, you have the option to set the level of prediction intervals according to your requirements. TimeGPT uses conformal prediction to calibrate the intervals.\n",
    "\n",
    "Here's how you could do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt_fcst_pred_int_df = timegpt.forecast(\n",
    "    df=df, h=12, freq='MS', level=[80, 90], \n",
    "    time_col='timestamp', target_col='value',\n",
    ")\n",
    "timegpt_fcst_pred_int_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_with_fcst_df = pd.concat([df, timegpt_fcst_pred_int_df])\n",
    "ax = history_with_fcst_df[['timestamp', 'value', 'TimeGPT']].set_index('timestamp').plot(figsize=(20, 10))\n",
    "for level, alpha in zip([80, 90], [0.4, 0.2]):\n",
    "    plt.fill_between(\n",
    "        history_with_fcst_df['timestamp'], \n",
    "        history_with_fcst_df[f'TimeGPT-lo-{level}'], \n",
    "        history_with_fcst_df[f'TimeGPT-hi-{level}'], \n",
    "        color='orange', \n",
    "        alpha=alpha,\n",
    "        label=f'TimeGPT-level-{level}]'\n",
    "    )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's essential to note that the choice of prediction interval level depends on your specific use case. For high-stakes predictions, you might want a wider interval to account for more uncertainty. For less critical forecasts, a narrower interval might be acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning is a process of further training a pre-existing model (like TimeGPT) on a specific task or dataset. This allows you to leverage the general language understanding capabilities of the pre-trained model and adapt it to your specific use case. \n",
    "\n",
    "In TimeGPT, you can use the `finetune_steps` argument to specify the number of additional training steps the model should undergo on your time series data. This helps in refining the model's understanding and prediction of your data patterns. \n",
    "\n",
    "Here's an example of how to fine-tune TimeGPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt_fcst_finetune_df = timegpt.forecast(\n",
    "    df=df, h=12, freq='MS', finetune_steps=10,\n",
    "    time_col='timestamp', target_col='value',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, timegpt_fcst_finetune_df]).set_index('timestamp').plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, `finetune_steps: 10` means the model will go through 10 iterations of training on your time series data.\n",
    "\n",
    "Keep in mind that fine-tuning can be a bit of trial and error. You might need to adjust the number of `finetune_steps` based on your specific needs and the complexity of your data. It's recommended to monitor the model's performance during fine-tuning and adjust as needed. Be aware that more `finetune_steps` may lead to longer training times and could potentially lead to overfitting if not managed properly. \n",
    "\n",
    "Remember, fine-tuning is a powerful feature, but it should be used thoughtfully and carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeGPT provides a robust solution for multi-series forecasting, which involves analyzing multiple data series concurrently, rather than a single one. The tool can be fine-tuned using a broad collection of series, enabling you to tailor the model to suit your specific needs or tasks.\n",
    "\n",
    "The following dataset contains prices of different electricity markets. Let see how can we forecast them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this series using [`StatsForecast`](https://github.com/Nixtla/statsforecast):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot(df, engine='matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just have to pass the dataframe to create forecasts for all the time series at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt_fcst_multiseries_df = timegpt.forecast(df=df, h=24, freq='H', level=[80, 90])\n",
    "timegpt_fcst_multiseries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot(df, timegpt_fcst_multiseries_df, max_insample_length=365, level=[80, 90], engine='matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exogenous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exogenous variables or external factors are crucial in time series forecasting as they provide additional information that might influence the prediction. These variables could include holiday markers, marketing spending, weather data, or any other external data that correlate with the time series data you are forecasting.\n",
    "\n",
    "For example, if you're forecasting ice cream sales, temperature data could serve as a useful exogenous variable. On hotter days, ice cream sales may increase.\n",
    "\n",
    "To incorporate exogenous variables in TimeGPT, you'll need to pair each point in your time series data with the corresponding external data.\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce forecasts we have to add the future values of the exogenous variables. Let's read this dataset. In this case we want to predict 24 steps ahead, therefore each unique id will have 24 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ex_vars_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-future-ex-vars.csv')\n",
    "future_ex_vars_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the `forecast` method, adding this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt_fcst_ex_vars_df = timegpt.forecast(df=df, X_df=future_ex_vars_df, h=24, freq='H', level=[80, 90])\n",
    "timegpt_fcst_ex_vars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot(df[['unique_id', 'ds', 'y']], timegpt_fcst_ex_vars_df, max_insample_length=365, level=[80, 90], engine='matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can get the importance of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timegpt.weights_x.plot.barh(x='features', y='weights')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
